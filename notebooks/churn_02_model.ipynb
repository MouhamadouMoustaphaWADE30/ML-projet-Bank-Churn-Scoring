{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojhMZWuavTzR"
   },
   "source": [
    "# Préparation de l'environnement pour le chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CORSY3zRq80D"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xzv8KJJmvkxq"
   },
   "source": [
    "## Chargement des bibliothèques de base et création des répertoires de travail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "a0sOiq_6rNYO"
   },
   "outputs": [],
   "source": [
    "#Importer pandas\n",
    "import pandas as pd\n",
    "# instruction permettant d'afficher,\n",
    "# par défaut, toutes les colonnes d'un dataframe\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2r-2h5zv2Hg"
   },
   "source": [
    "## Téléchargement des données et mise à la disposition de google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RrXMnb_srlwK"
   },
   "outputs": [],
   "source": [
    "#Utiliser la mémoire de google drive pour stocker les données et pouvoir faire les calculs\n",
    "## Télécharger les données depuis l'id du fichier drive.\n",
    "# train_id = '12LCqi7P3W-waGngWxF3FNP2Lbt9hYU0I' #train 1mdqBCvaVbar1TyuOe5Cg5Grp49TrUnnM\n",
    "# test_id = '1HjoXeXkOvgDP0vZuJzi1zGpon2wEuwKt' #test\n",
    "# # Definition des chemins destination  for les fichiers téléchargés\n",
    "# DATA_DIR = '/home/data/'\n",
    "# destination_path_1 = Path(DATA_DIR, 'train.csv')\n",
    "# destination_path_2 = Path(DATA_DIR, 'to_predict.csv')\n",
    "# !mkdir /home/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-09T17:31:18.862716Z",
     "iopub.status.busy": "2024-06-09T17:31:18.862716Z",
     "iopub.status.idle": "2024-06-09T17:31:18.867928Z",
     "shell.execute_reply": "2024-06-09T17:31:18.866919Z",
     "shell.execute_reply.started": "2024-06-09T17:31:18.862716Z"
    },
    "id": "y0rzf-kttEkp",
    "outputId": "2aa2aa6c-133e-4b5d-a920-089bc70f2287",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Download the files from Google Drive\n",
    "# !gdown --id $train_id -O $destination_path_1\n",
    "# !gdown --id $test_id -O $destination_path_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "cx9ZdnRAub72"
   },
   "outputs": [],
   "source": [
    "# Bibliothques nécessaires\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import (balanced_accuracy_score, roc_auc_score,\n",
    "                             confusion_matrix, classification_report)\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Imblearn\n",
    "from imblearn.pipeline import Pipeline as Pipeline_imb\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.under_sampling import RandomUnderSampler,TomekLinks\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCDO1g5_wCIa"
   },
   "source": [
    "## Chargement des données dans le notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "ISf2y6YotKDW",
    "outputId": "aedb86c2-84ae-441e-a75c-db1bd79f2728"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15674932</td>\n",
       "      <td>Okwudilichukwu</td>\n",
       "      <td>668</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181449.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15749177</td>\n",
       "      <td>Okwudiliolisa</td>\n",
       "      <td>627</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49503.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15694510</td>\n",
       "      <td>Hsueh</td>\n",
       "      <td>678</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184866.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  CustomerId         Surname  CreditScore Geography Gender   Age  Tenure  \\\n",
       "0   0    15674932  Okwudilichukwu          668    France   Male  33.0       3   \n",
       "1   1    15749177   Okwudiliolisa          627    France   Male  33.0       1   \n",
       "2   2    15694510           Hsueh          678    France   Male  40.0      10   \n",
       "\n",
       "   Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0      0.0              2        1.0             0.0        181449.97       0  \n",
       "1      0.0              2        1.0             1.0         49503.50       0  \n",
       "2      0.0              2        1.0             0.0        184866.69       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final train après EDA\n",
    "train = pd.read_csv(\"../bases/train.csv\")\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxF0k8TywBeT"
   },
   "source": [
    "# 1. Préprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "szBzHQ-dugB6",
    "outputId": "c0fcf374-bcb9-453b-f4df-87011aa9a203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 165034 entries, 0 to 165033\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   id               165034 non-null  int64  \n",
      " 1   CustomerId       165034 non-null  int64  \n",
      " 2   Surname          165034 non-null  object \n",
      " 3   CreditScore      165034 non-null  int64  \n",
      " 4   Geography        165034 non-null  object \n",
      " 5   Gender           165034 non-null  object \n",
      " 6   Age              165034 non-null  float64\n",
      " 7   Tenure           165034 non-null  int64  \n",
      " 8   Balance          165034 non-null  float64\n",
      " 9   NumOfProducts    165034 non-null  int64  \n",
      " 10  HasCrCard        165034 non-null  float64\n",
      " 11  IsActiveMember   165034 non-null  float64\n",
      " 12  EstimatedSalary  165034 non-null  float64\n",
      " 13  Exited           165034 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(3)\n",
      "memory usage: 17.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pCnTsalLvDxj"
   },
   "outputs": [],
   "source": [
    "X =train.drop(['Exited', 'id', 'CustomerId', 'Surname'], axis = 1)\n",
    "#X = train.drop(['Exited'], axis = 1) #\n",
    "y = train['Exited']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42 )\n",
    "\n",
    "del train # Suppression du jeu de donnée de la mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DSvjEgvSyYX_"
   },
   "outputs": [],
   "source": [
    "numerical_features = X_train.select_dtypes(include = ['number']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include = ['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrNPntDJw6Ae"
   },
   "source": [
    "# 2. Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rYoVZ_V5vMRW"
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "train_auc = []\n",
    "test_auc = []\n",
    "cv = StratifiedKFold(n_splits = 3, random_state = 30, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxkFBoGlyE8X"
   },
   "source": [
    "## 2.1 Modeles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WmhG4vNuyJbe"
   },
   "source": [
    "### 2.1.1 Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hGjDQw85yHcG"
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        ('numerical_preprocess', StandardScaler(), numerical_features),\n",
    "        ('categorical_preprocess', OneHotEncoder(drop = 'first'),categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline\n",
    "pipe = Pipeline_imb(\n",
    "    [\n",
    "        ('Resampling', RandomUnderSampler(random_state = 42)),\n",
    "        ('preprocessing', ct),\n",
    "        ('model', LogisticRegression())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNkWR2tG0BWL"
   },
   "source": [
    "#### Définition d'une fonction pour entrainer les modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXSiYofH-wyI"
   },
   "source": [
    "Paramètres de rééchantillonnage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tCyL6qqHz31f"
   },
   "outputs": [],
   "source": [
    "# Definition des paramètres d'échantillonage vu que les données sont déséquilibrées.\n",
    "params_sampler = [\n",
    "    #  paramètres de sous-échantillonage\n",
    "    {'randomundersampler__sampling_strategy' : (0.8, 0.7, 0.6),},\n",
    "   #{'tomeklinks__n_jobs' : (None, 2, 3)},\n",
    "    {'randomoversampler__sampling_strategy' : (0.4, 0.5, 0.7) },\n",
    "    # Paramètres de sur-échantillonage\n",
    "    {'' : ('temp1', 'temp2')},\n",
    "    #{'adasyn__n_neighbors' : (5, 7, 9) }\n",
    "]\n",
    "# L'idée ici est de tester plusieurs paramètres de réechantillonage en vue d'en sélectionner celles qui présentent les meilleurs résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_ItOORr-wRY"
   },
   "source": [
    "Définition de la fonction proprement dite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PvAnIwDd_J5t"
   },
   "outputs": [],
   "source": [
    "def pipelines_and_search(model, params_sampler, params_model, X_train, y_train, cv):\n",
    "    \"\"\"\n",
    "    Crée une liste de pipelines pour le modèle spécifié et effectue une recherche de grille pour chaque pipeline.\n",
    "    Parameters:\n",
    "    model (estimator): Le modèle à utiliser dans les pipelines (par exemple, LogisticRegression()).\n",
    "    params_sampler (list): Liste des paramètres pour les méthodes de rééchantillonnage définie plus haut\n",
    "    params_model (dict): Dictionnaire des paramètres pour le modèle.\n",
    "    X_train (array-like): Les données d'entraînement.\n",
    "    y_train (array-like): Les étiquettes de classe pour les données d'entraînement.\n",
    "    cv (int or cross-validation generator): La stratégie de validation croisée.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Liste des scores et des objets GridSearchCV.\n",
    "    \"\"\"\n",
    "    pipelines = [\n",
    "        # Méthodes de sous-échantillonnage\n",
    "        make_pipeline_imb(ct, RandomUnderSampler(random_state=42), model),\n",
    "        # make_pipeline_imb(ct, TomekLinks(), model),\n",
    "        make_pipeline_imb(ct, RandomOverSampler(random_state = 42), model),\n",
    "        # Méthodes de sur-échantillonnage\n",
    "        make_pipeline_imb(ct, SMOTE(), model),\n",
    "        # make_pipeline_imb(ct, ADASYN(), model)\n",
    "    ]\n",
    "\n",
    "    best_scores = []\n",
    "    grid_list = []\n",
    "\n",
    "    for i, pipe in enumerate(pipelines):\n",
    "        params = params_sampler[i].copy()\n",
    "        params.update(params_model)\n",
    "        params.pop('', None)\n",
    "        print(f\"--------------------------------------------------------------------------\\n Working on : {params}\")\n",
    "\n",
    "        pipe_GridCV = GridSearchCV(pipe, param_grid=params, cv=cv, scoring='roc_auc')\n",
    "        grid_list.append(pipe_GridCV)\n",
    "\n",
    "        pipe_GridCV.fit(X_train, y_train)\n",
    "\n",
    "        print(f\"Best_score : {pipe_GridCV.best_score_}\")\n",
    "        print(f\"Best_params : {pipe_GridCV.best_params_}\")\n",
    "        best_scores.append(pipe_GridCV.best_score_)\n",
    "\n",
    "    return best_scores, grid_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5PemHJts_Poa"
   },
   "outputs": [],
   "source": [
    "# Définition des paramètres pour la régression logistique\n",
    "params_reg_logistic = {#'logisticregression__max_iter' : (1000, 5000),\n",
    "                'logisticregression__C' : (0.50, 1 ,0.7)\n",
    "                       }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C4xeC0V8_n-t",
    "outputId": "77433838-5d98-4691-8f19-2ad070f11c48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      " Working on : {'randomundersampler__sampling_strategy': (0.8, 0.7, 0.6), 'logisticregression__C': (0.5, 1, 0.7)}\n",
      "Best_score : 0.819535601687436\n",
      "Best_params : {'logisticregression__C': 0.5, 'randomundersampler__sampling_strategy': 0.8}\n",
      "--------------------------------------------------------------------------\n",
      " Working on : {'randomoversampler__sampling_strategy': (0.4, 0.5, 0.7), 'logisticregression__C': (0.5, 1, 0.7)}\n",
      "Best_score : 0.8194766030615899\n",
      "Best_params : {'logisticregression__C': 0.5, 'randomoversampler__sampling_strategy': 0.7}\n",
      "--------------------------------------------------------------------------\n",
      " Working on : {'logisticregression__C': (0.5, 1, 0.7)}\n",
      "Best_score : 0.8195889194605753\n",
      "Best_params : {'logisticregression__C': 0.7}\n",
      "CPU times: total: 1min 11s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_reg = pipelines_and_search(LogisticRegression(), params_sampler, params_reg_logistic, X_train, y_train, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JvDmmZVFBgnb",
    "outputId": "b317dd32-80d6-4408-965b-ecf86b5f2f1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs scores pour chaque pipeline :\n",
      "0.819535601687436\n",
      "0.8194766030615899\n",
      "0.8195889194605753\n"
     ]
    }
   ],
   "source": [
    "# Afficher les meilleurs scores\n",
    "print(\"Meilleurs scores pour chaque pipeline :\")\n",
    "for score in log_reg[0]:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5xsHfQEJOdy",
    "outputId": "ab38ccc0-af04-4895-da8c-75e2927d6406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Meilleurs paramètres pour chaque pipeline :\n",
      "{'logisticregression__C': 0.5, 'randomundersampler__sampling_strategy': 0.8}\n",
      "{'logisticregression__C': 0.5, 'randomoversampler__sampling_strategy': 0.7}\n",
      "{'logisticregression__C': 0.7}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Accéder aux meilleurs paramètres pour chaque GridSearchCV\n",
    "print(\"\\nMeilleurs paramètres pour chaque pipeline :\")\n",
    "for grid in log_reg[1]:\n",
    "    print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iG23X2coJe3e",
    "outputId": "52092696-8c00-4755-b650-3249cebff267"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Accéder aux objets GridSearchCV pour d\\'autres informations, par exemple :\\nprint(\"\\nDétails complets de chaque GridSearchCV :\")\\nfor i, grid in enumerate(log_reg[1]):\\n    print(f\"Pipeline {i+1}:\")\\n    print(f\"Best Score: {grid.best_score_}\")\\n    print(f\"Best Params: {grid.best_params_}\")\\n    # Accéder aux scores de toutes les combinaisons de paramètres testées\\n    print(f\"CV Results: {grid.cv_results_}\")\\n    '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Accéder aux objets GridSearchCV pour d'autres informations, par exemple :\n",
    "print(\"\\nDétails complets de chaque GridSearchCV :\")\n",
    "for i, grid in enumerate(log_reg[1]):\n",
    "    print(f\"Pipeline {i+1}:\")\n",
    "    print(f\"Best Score: {grid.best_score_}\")\n",
    "    print(f\"Best Params: {grid.best_params_}\")\n",
    "    # Accéder aux scores de toutes les combinaisons de paramètres testées\n",
    "    print(f\"CV Results: {grid.cv_results_}\")\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "ubDyO8wwJtKr",
    "outputId": "ddbd2114-6c99-474d-fd01-b2e424a41726"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_preprocess&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;CreditScore&#x27;, &#x27;Age&#x27;,\n",
       "                                                   &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                                   &#x27;IsActiveMember&#x27;,\n",
       "                                                   &#x27;EstimatedSalary&#x27;]),\n",
       "                                                 (&#x27;categorical_preprocess&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                                  [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])),\n",
       "                (&#x27;smote&#x27;, SMOTE()),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression(C=0.7))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_preprocess&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;CreditScore&#x27;, &#x27;Age&#x27;,\n",
       "                                                   &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                                   &#x27;IsActiveMember&#x27;,\n",
       "                                                   &#x27;EstimatedSalary&#x27;]),\n",
       "                                                 (&#x27;categorical_preprocess&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                                  [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])),\n",
       "                (&#x27;smote&#x27;, SMOTE()),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression(C=0.7))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numerical_preprocess&#x27;, StandardScaler(),\n",
       "                                 [&#x27;CreditScore&#x27;, &#x27;Age&#x27;, &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                  &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                  &#x27;IsActiveMember&#x27;, &#x27;EstimatedSalary&#x27;]),\n",
       "                                (&#x27;categorical_preprocess&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                 [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_preprocess</label><div class=\"sk-toggleable__content\"><pre>[&#x27;CreditScore&#x27;, &#x27;Age&#x27;, &#x27;Tenure&#x27;, &#x27;Balance&#x27;, &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;, &#x27;IsActiveMember&#x27;, &#x27;EstimatedSalary&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical_preprocess</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Geography&#x27;, &#x27;Gender&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.7)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('numerical_preprocess',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['CreditScore', 'Age',\n",
       "                                                   'Tenure', 'Balance',\n",
       "                                                   'NumOfProducts', 'HasCrCard',\n",
       "                                                   'IsActiveMember',\n",
       "                                                   'EstimatedSalary']),\n",
       "                                                 ('categorical_preprocess',\n",
       "                                                  OneHotEncoder(drop='first'),\n",
       "                                                  ['Geography', 'Gender'])])),\n",
       "                ('smote', SMOTE()),\n",
       "                ('logisticregression', LogisticRegression(C=0.7))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_index = pd.DataFrame({\"Best_score\" : log_reg[0]}).sort_values(by = 'Best_score',\n",
    "                                                                   ascending = False).index[0]\n",
    "best_model_LG = log_reg[1][best_model_index].best_estimator_\n",
    "best_model_LG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_names = [name for name, _ in best_model_LG.steps]\n",
    "\n",
    "train_auc_LG = roc_auc_score(y_train, best_model_LG.predict_proba(X_train)[:, 1])\n",
    "test_auc_LG = roc_auc_score(y_test, best_model_LG.predict_proba(X_test)[:, 1])\n",
    "model = step_names[1] + \" + \" +  step_names[-1]\n",
    "\n",
    "train_auc.append(train_auc_LG)\n",
    "test_auc.append(test_auc_LG)\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>avg_pre</th>\n",
       "      <th>avg_rec</th>\n",
       "      <th>avg_spe</th>\n",
       "      <th>avg_f1</th>\n",
       "      <th>avg_geo</th>\n",
       "      <th>avg_iba</th>\n",
       "      <th>total_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pre</th>\n",
       "      <td>0.913213</td>\n",
       "      <td>0.451672</td>\n",
       "      <td>0.815556</td>\n",
       "      <td>0.75535</td>\n",
       "      <td>0.736896</td>\n",
       "      <td>0.77314</td>\n",
       "      <td>0.745951</td>\n",
       "      <td>0.55747</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec</th>\n",
       "      <td>0.762120</td>\n",
       "      <td>0.730126</td>\n",
       "      <td>0.815556</td>\n",
       "      <td>0.75535</td>\n",
       "      <td>0.736896</td>\n",
       "      <td>0.77314</td>\n",
       "      <td>0.745951</td>\n",
       "      <td>0.55747</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spe</th>\n",
       "      <td>0.730126</td>\n",
       "      <td>0.762120</td>\n",
       "      <td>0.815556</td>\n",
       "      <td>0.75535</td>\n",
       "      <td>0.736896</td>\n",
       "      <td>0.77314</td>\n",
       "      <td>0.745951</td>\n",
       "      <td>0.55747</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.830853</td>\n",
       "      <td>0.558095</td>\n",
       "      <td>0.815556</td>\n",
       "      <td>0.75535</td>\n",
       "      <td>0.736896</td>\n",
       "      <td>0.77314</td>\n",
       "      <td>0.745951</td>\n",
       "      <td>0.55747</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo</th>\n",
       "      <td>0.745951</td>\n",
       "      <td>0.745951</td>\n",
       "      <td>0.815556</td>\n",
       "      <td>0.75535</td>\n",
       "      <td>0.736896</td>\n",
       "      <td>0.77314</td>\n",
       "      <td>0.745951</td>\n",
       "      <td>0.55747</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iba</th>\n",
       "      <td>0.558224</td>\n",
       "      <td>0.554663</td>\n",
       "      <td>0.815556</td>\n",
       "      <td>0.75535</td>\n",
       "      <td>0.736896</td>\n",
       "      <td>0.77314</td>\n",
       "      <td>0.745951</td>\n",
       "      <td>0.55747</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sup</th>\n",
       "      <td>32529.000000</td>\n",
       "      <td>8730.000000</td>\n",
       "      <td>0.815556</td>\n",
       "      <td>0.75535</td>\n",
       "      <td>0.736896</td>\n",
       "      <td>0.77314</td>\n",
       "      <td>0.745951</td>\n",
       "      <td>0.55747</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1   avg_pre  avg_rec   avg_spe   avg_f1  \\\n",
       "pre      0.913213     0.451672  0.815556  0.75535  0.736896  0.77314   \n",
       "rec      0.762120     0.730126  0.815556  0.75535  0.736896  0.77314   \n",
       "spe      0.730126     0.762120  0.815556  0.75535  0.736896  0.77314   \n",
       "f1       0.830853     0.558095  0.815556  0.75535  0.736896  0.77314   \n",
       "geo      0.745951     0.745951  0.815556  0.75535  0.736896  0.77314   \n",
       "iba      0.558224     0.554663  0.815556  0.75535  0.736896  0.77314   \n",
       "sup  32529.000000  8730.000000  0.815556  0.75535  0.736896  0.77314   \n",
       "\n",
       "      avg_geo  avg_iba  total_support  \n",
       "pre  0.745951  0.55747          41259  \n",
       "rec  0.745951  0.55747          41259  \n",
       "spe  0.745951  0.55747          41259  \n",
       "f1   0.745951  0.55747          41259  \n",
       "geo  0.745951  0.55747          41259  \n",
       "iba  0.745951  0.55747          41259  \n",
       "sup  0.745951  0.55747          41259  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report_imbalanced(y_test, best_model_LG.predict(X_test), output_dict = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, best_model_LG.predict(X_test), normalize=\"true\"),\n",
    "           annot=True, fmt='.2g', cmap=\"Greens\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUoHnkvKvB9e"
   },
   "source": [
    "### 2.1.2 Naives Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xIPSmujTcEFz",
    "outputId": "90e4807e-7592-4a92-8b4b-a056ad035f1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      " Working on : {'randomundersampler__sampling_strategy': (0.8, 0.7, 0.6), 'gaussiannb__var_smoothing': [1e-09, 1e-08, 1e-07]}\n",
      "Best_score : 0.8179470953839152\n",
      "Best_params : {'gaussiannb__var_smoothing': 1e-07, 'randomundersampler__sampling_strategy': 0.8}\n",
      "--------------------------------------------------------------------------\n",
      " Working on : {'randomoversampler__sampling_strategy': (0.4, 0.5, 0.7), 'gaussiannb__var_smoothing': [1e-09, 1e-08, 1e-07]}\n",
      "Best_score : 0.816438218180546\n",
      "Best_params : {'gaussiannb__var_smoothing': 1e-07, 'randomoversampler__sampling_strategy': 0.5}\n",
      "--------------------------------------------------------------------------\n",
      " Working on : {'gaussiannb__var_smoothing': [1e-09, 1e-08, 1e-07]}\n",
      "Best_score : 0.8138083559992687\n",
      "Best_params : {'gaussiannb__var_smoothing': 1e-09}\n",
      "CPU times: total: 1min\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Naive Bayes\n",
    "params_naive_bayes = {'gaussiannb__var_smoothing': [1e-9, 1e-8, 1e-7]}\n",
    "naive_bayes = pipelines_and_search(GaussianNB(), params_sampler, params_naive_bayes, X_train, y_train, cv)\n",
    "#log_reg = pipelines_and_search(LogisticRegression(), params_sampler, params_reg_logistic, X_train, y_train, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BdtkHffQyspS",
    "outputId": "b157812a-c2d1-449e-9dca-72a5ac3a32b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs scores pour chaque pipeline :\n",
      "0.8179470953839152\n",
      "0.816438218180546\n",
      "0.8138083559992687\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleurs scores pour chaque pipeline :\")\n",
    "for score in naive_bayes[0]:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oy9k1V5Lq2Hn",
    "outputId": "ecde2f0a-4fe4-461d-bec8-30afcc5f1887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Meilleurs paramètres pour chaque pipeline :\n",
      "{'gaussiannb__var_smoothing': 1e-07, 'randomundersampler__sampling_strategy': 0.8}\n",
      "{'gaussiannb__var_smoothing': 1e-07, 'randomoversampler__sampling_strategy': 0.5}\n",
      "{'gaussiannb__var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "# Accéder aux meilleurs paramètres pour chaque GridSearchCV\n",
    "print(\"\\nMeilleurs paramètres pour chaque pipeline :\")\n",
    "for grid in naive_bayes[1]:\n",
    "    print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "id": "r6CllcuD0Lw5",
    "outputId": "ae40ca2c-4d03-4db0-bab1-390cec3d8248",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_preprocess&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;CreditScore&#x27;, &#x27;Age&#x27;,\n",
       "                                                   &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                                   &#x27;IsActiveMember&#x27;,\n",
       "                                                   &#x27;EstimatedSalary&#x27;]),\n",
       "                                                 (&#x27;categorical_preprocess&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                                  [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])),\n",
       "                (&#x27;randomundersampler&#x27;,\n",
       "                 RandomUnderSampler(random_state=42, sampling_strategy=0.8)),\n",
       "                (&#x27;gaussiannb&#x27;, GaussianNB(var_smoothing=1e-07))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_preprocess&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;CreditScore&#x27;, &#x27;Age&#x27;,\n",
       "                                                   &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                                   &#x27;IsActiveMember&#x27;,\n",
       "                                                   &#x27;EstimatedSalary&#x27;]),\n",
       "                                                 (&#x27;categorical_preprocess&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                                  [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])),\n",
       "                (&#x27;randomundersampler&#x27;,\n",
       "                 RandomUnderSampler(random_state=42, sampling_strategy=0.8)),\n",
       "                (&#x27;gaussiannb&#x27;, GaussianNB(var_smoothing=1e-07))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numerical_preprocess&#x27;, StandardScaler(),\n",
       "                                 [&#x27;CreditScore&#x27;, &#x27;Age&#x27;, &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                  &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                  &#x27;IsActiveMember&#x27;, &#x27;EstimatedSalary&#x27;]),\n",
       "                                (&#x27;categorical_preprocess&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                 [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_preprocess</label><div class=\"sk-toggleable__content\"><pre>[&#x27;CreditScore&#x27;, &#x27;Age&#x27;, &#x27;Tenure&#x27;, &#x27;Balance&#x27;, &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;, &#x27;IsActiveMember&#x27;, &#x27;EstimatedSalary&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical_preprocess</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Geography&#x27;, &#x27;Gender&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=42, sampling_strategy=0.8)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB(var_smoothing=1e-07)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('numerical_preprocess',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['CreditScore', 'Age',\n",
       "                                                   'Tenure', 'Balance',\n",
       "                                                   'NumOfProducts', 'HasCrCard',\n",
       "                                                   'IsActiveMember',\n",
       "                                                   'EstimatedSalary']),\n",
       "                                                 ('categorical_preprocess',\n",
       "                                                  OneHotEncoder(drop='first'),\n",
       "                                                  ['Geography', 'Gender'])])),\n",
       "                ('randomundersampler',\n",
       "                 RandomUnderSampler(random_state=42, sampling_strategy=0.8)),\n",
       "                ('gaussiannb', GaussianNB(var_smoothing=1e-07))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_index = pd.DataFrame({\"Best_score\" : naive_bayes[0]}).sort_values(by = 'Best_score',\n",
    "                                                                   ascending = False).index[0]\n",
    "best_model_NB = naive_bayes[1][best_model_index].best_estimator_\n",
    "best_model_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_names = [name for name, _ in best_model_NB.steps]\n",
    "\n",
    "train_auc_NB = roc_auc_score(y_train, best_model_NB.predict_proba(X_train)[:, 1])\n",
    "test_auc_NB = roc_auc_score(y_test, best_model_NB.predict_proba(X_test)[:, 1])\n",
    "model = step_names[1] + \" + \" +  step_names[-1]\n",
    "\n",
    "train_auc.append(train_auc_NB)\n",
    "test_auc.append(test_auc_NB)\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>avg_pre</th>\n",
       "      <th>avg_rec</th>\n",
       "      <th>avg_spe</th>\n",
       "      <th>avg_f1</th>\n",
       "      <th>avg_geo</th>\n",
       "      <th>avg_iba</th>\n",
       "      <th>total_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pre</th>\n",
       "      <td>0.898978</td>\n",
       "      <td>0.452264</td>\n",
       "      <td>0.804457</td>\n",
       "      <td>0.758356</td>\n",
       "      <td>0.695799</td>\n",
       "      <td>0.773582</td>\n",
       "      <td>0.725053</td>\n",
       "      <td>0.52899</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec</th>\n",
       "      <td>0.781303</td>\n",
       "      <td>0.672852</td>\n",
       "      <td>0.804457</td>\n",
       "      <td>0.758356</td>\n",
       "      <td>0.695799</td>\n",
       "      <td>0.773582</td>\n",
       "      <td>0.725053</td>\n",
       "      <td>0.52899</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spe</th>\n",
       "      <td>0.672852</td>\n",
       "      <td>0.781303</td>\n",
       "      <td>0.804457</td>\n",
       "      <td>0.758356</td>\n",
       "      <td>0.695799</td>\n",
       "      <td>0.773582</td>\n",
       "      <td>0.725053</td>\n",
       "      <td>0.52899</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.836020</td>\n",
       "      <td>0.540934</td>\n",
       "      <td>0.804457</td>\n",
       "      <td>0.758356</td>\n",
       "      <td>0.695799</td>\n",
       "      <td>0.773582</td>\n",
       "      <td>0.725053</td>\n",
       "      <td>0.52899</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo</th>\n",
       "      <td>0.725053</td>\n",
       "      <td>0.725053</td>\n",
       "      <td>0.804457</td>\n",
       "      <td>0.758356</td>\n",
       "      <td>0.695799</td>\n",
       "      <td>0.773582</td>\n",
       "      <td>0.725053</td>\n",
       "      <td>0.52899</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iba</th>\n",
       "      <td>0.531403</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.804457</td>\n",
       "      <td>0.758356</td>\n",
       "      <td>0.695799</td>\n",
       "      <td>0.773582</td>\n",
       "      <td>0.725053</td>\n",
       "      <td>0.52899</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sup</th>\n",
       "      <td>32529.000000</td>\n",
       "      <td>8730.000000</td>\n",
       "      <td>0.804457</td>\n",
       "      <td>0.758356</td>\n",
       "      <td>0.695799</td>\n",
       "      <td>0.773582</td>\n",
       "      <td>0.725053</td>\n",
       "      <td>0.52899</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1   avg_pre   avg_rec   avg_spe    avg_f1  \\\n",
       "pre      0.898978     0.452264  0.804457  0.758356  0.695799  0.773582   \n",
       "rec      0.781303     0.672852  0.804457  0.758356  0.695799  0.773582   \n",
       "spe      0.672852     0.781303  0.804457  0.758356  0.695799  0.773582   \n",
       "f1       0.836020     0.540934  0.804457  0.758356  0.695799  0.773582   \n",
       "geo      0.725053     0.725053  0.804457  0.758356  0.695799  0.773582   \n",
       "iba      0.531403     0.520000  0.804457  0.758356  0.695799  0.773582   \n",
       "sup  32529.000000  8730.000000  0.804457  0.758356  0.695799  0.773582   \n",
       "\n",
       "      avg_geo  avg_iba  total_support  \n",
       "pre  0.725053  0.52899          41259  \n",
       "rec  0.725053  0.52899          41259  \n",
       "spe  0.725053  0.52899          41259  \n",
       "f1   0.725053  0.52899          41259  \n",
       "geo  0.725053  0.52899          41259  \n",
       "iba  0.725053  0.52899          41259  \n",
       "sup  0.725053  0.52899          41259  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report_imbalanced(y_test, best_model_NB.predict(X_test), output_dict = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_names = [name for name, _ in best_model_NB.steps]\n",
    "\n",
    "train_auc_NB = roc_auc_score(y_train, best_model_NB.predict_proba(X_train)[:, 1])\n",
    "test_auc_NB = roc_auc_score(y_test, best_model_NB.predict_proba(X_test)[:, 1])\n",
    "model = step_names[1] + \" + \" +  step_names[-1]\n",
    "\n",
    "train_auc.append(train_auc_NB)\n",
    "test_auc.append(test_auc_NB)\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>avg_pre</th>\n",
       "      <th>avg_rec</th>\n",
       "      <th>avg_spe</th>\n",
       "      <th>avg_f1</th>\n",
       "      <th>avg_geo</th>\n",
       "      <th>avg_iba</th>\n",
       "      <th>total_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pre</th>\n",
       "      <td>0.898978</td>\n",
       "      <td>0.452264</td>\n",
       "      <td>0.804457</td>\n",
       "      <td>0.758356</td>\n",
       "      <td>0.695799</td>\n",
       "      <td>0.773582</td>\n",
       "      <td>0.725053</td>\n",
       "      <td>0.52899</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec</th>\n",
       "      <td>0.781303</td>\n",
       "      <td>0.672852</td>\n",
       "      <td>0.804457</td>\n",
       "      <td>0.758356</td>\n",
       "      <td>0.695799</td>\n",
       "      <td>0.773582</td>\n",
       "      <td>0.725053</td>\n",
       "      <td>0.52899</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spe</th>\n",
       "      <td>0.672852</td>\n",
       "      <td>0.781303</td>\n",
       "      <td>0.804457</td>\n",
       "      <td>0.758356</td>\n",
       "      <td>0.695799</td>\n",
       "      <td>0.773582</td>\n",
       "      <td>0.725053</td>\n",
       "      <td>0.52899</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.836020</td>\n",
       "      <td>0.540934</td>\n",
       "      <td>0.804457</td>\n",
       "      <td>0.758356</td>\n",
       "      <td>0.695799</td>\n",
       "      <td>0.773582</td>\n",
       "      <td>0.725053</td>\n",
       "      <td>0.52899</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo</th>\n",
       "      <td>0.725053</td>\n",
       "      <td>0.725053</td>\n",
       "      <td>0.804457</td>\n",
       "      <td>0.758356</td>\n",
       "      <td>0.695799</td>\n",
       "      <td>0.773582</td>\n",
       "      <td>0.725053</td>\n",
       "      <td>0.52899</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iba</th>\n",
       "      <td>0.531403</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.804457</td>\n",
       "      <td>0.758356</td>\n",
       "      <td>0.695799</td>\n",
       "      <td>0.773582</td>\n",
       "      <td>0.725053</td>\n",
       "      <td>0.52899</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sup</th>\n",
       "      <td>32529.000000</td>\n",
       "      <td>8730.000000</td>\n",
       "      <td>0.804457</td>\n",
       "      <td>0.758356</td>\n",
       "      <td>0.695799</td>\n",
       "      <td>0.773582</td>\n",
       "      <td>0.725053</td>\n",
       "      <td>0.52899</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1   avg_pre   avg_rec   avg_spe    avg_f1  \\\n",
       "pre      0.898978     0.452264  0.804457  0.758356  0.695799  0.773582   \n",
       "rec      0.781303     0.672852  0.804457  0.758356  0.695799  0.773582   \n",
       "spe      0.672852     0.781303  0.804457  0.758356  0.695799  0.773582   \n",
       "f1       0.836020     0.540934  0.804457  0.758356  0.695799  0.773582   \n",
       "geo      0.725053     0.725053  0.804457  0.758356  0.695799  0.773582   \n",
       "iba      0.531403     0.520000  0.804457  0.758356  0.695799  0.773582   \n",
       "sup  32529.000000  8730.000000  0.804457  0.758356  0.695799  0.773582   \n",
       "\n",
       "      avg_geo  avg_iba  total_support  \n",
       "pre  0.725053  0.52899          41259  \n",
       "rec  0.725053  0.52899          41259  \n",
       "spe  0.725053  0.52899          41259  \n",
       "f1   0.725053  0.52899          41259  \n",
       "geo  0.725053  0.52899          41259  \n",
       "iba  0.725053  0.52899          41259  \n",
       "sup  0.725053  0.52899          41259  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report_imbalanced(y_test, best_model_NB.predict(X_test), output_dict = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, best_model_NB.predict(X_test), normalize=\"true\"),\n",
    "           annot=True, fmt='.2g', cmap=\"Greens\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20ilcN1JvLGs"
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "ANyreHDNyL-e"
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "# params_svm = {'svc__C': [0.1, 1, 1.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZrkyrWqzZ2a",
    "outputId": "20a99420-6644-469e-c029-855b71940790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      " Working on : {'randomundersampler__sampling_strategy': (0.8, 0.7, 0.6), 'svc__C': [0.1, 1, 1.5]}\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# svm_model = pipelines_and_search(SVC(probability=True), params_sampler, params_svm, X_train, y_train, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6l19lhMzdmB"
   },
   "outputs": [],
   "source": [
    "# best_model_index = pd.DataFrame({\"Best_score\" : svm_model[0]}).sort_values(by = 'Best_score',\n",
    "                                                                   # ascending = False).index[0]\n",
    "# best_svm_model = svm_model[1][best_model_index].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLe5oFAqAnTX"
   },
   "outputs": [],
   "source": [
    "# best_svm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMryGBaVvLX2"
   },
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmo2pHaRvLax"
   },
   "source": [
    "### 2.1.3 RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-L6fsYW79Apf"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Random Forest\n",
    "# params_random_forest = {'randomforestclassifier__n_estimators': [100, 200, 300]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNVPE7SP9Z89"
   },
   "outputs": [],
   "source": [
    "random_forest_model = pipelines_and_search(RandomForestClassifier(), params_sampler, params_random_forest, X_train, y_train, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yF9WgHtf-BhA"
   },
   "outputs": [],
   "source": [
    "best_model_index = pd.DataFrame({\"Best_score\" : random_forest_model[0]}).sort_values(by = 'Best_score',\n",
    "                                                                   ascending = False).index[0]\n",
    "best_random_forest_model = random_forest_model[1][best_model_index].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TqUHT-dA_yLo"
   },
   "outputs": [],
   "source": [
    "best_random_forest_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILUlPg2QvLdJ"
   },
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "UPCSJ0TVBAOV"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Gradient Boosting\n",
    "params_gb = {'gradientboostingclassifier__learning_rate': [0.01, 0.1], 'gradientboostingclassifier__max_depth': [3, 4]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "uIXob2z1GCVS",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "eef9296e-3e8e-4477-e88d-0f490c70cf3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      " Working on : {'randomundersampler__sampling_strategy': (0.8, 0.7, 0.6), 'gradientboostingclassifier__learning_rate': [0.01, 0.1], 'gradientboostingclassifier__max_depth': [3, 4]}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "Cell \u001b[1;32mIn[8], line 37\u001b[0m, in \u001b[0;36mpipelines_and_search\u001b[1;34m(model, params_sampler, params_model, X_train, y_train, cv)\u001b[0m\n\u001b[0;32m     34\u001b[0m pipe_GridCV \u001b[38;5;241m=\u001b[39m GridSearchCV(pipe, param_grid\u001b[38;5;241m=\u001b[39mparams, cv\u001b[38;5;241m=\u001b[39mcv, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m grid_list\u001b[38;5;241m.\u001b[39mappend(pipe_GridCV)\n\u001b[1;32m---> 37\u001b[0m \u001b[43mpipe_GridCV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest_score : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipe_GridCV\u001b[38;5;241m.\u001b[39mbest_score_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest_params : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipe_GridCV\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    727\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 729\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\imblearn\\pipeline.py:333\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    332\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 333\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:532\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    531\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 532\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:610\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    603\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[0;32m    604\u001b[0m             y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    605\u001b[0m             raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    606\u001b[0m             sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    607\u001b[0m         )\n\u001b[0;32m    609\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 610\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:245\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    242\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    244\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 245\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    248\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    249\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[0;32m    250\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    258\u001b[0m )\n",
      "File \u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gradient_boosting_model = pipelines_and_search(GradientBoostingClassifier(), params_sampler, params_gb, X_train, y_train, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r8H7RzaxGNZH"
   },
   "outputs": [],
   "source": [
    "best_gradient_boosting_model = pd.DataFrame({\"Best_score\" : gradient_boosting_model[0]}).sort_values(by = 'Best_score',\n",
    "                                                                   ascending = False).index[0]\n",
    "best_gradient_boosting_model = gradient_boosting_model[1][best_model_index].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRSn1hegGhkz"
   },
   "outputs": [],
   "source": [
    "best_gradient_boosting_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHMRuOd5vLfm"
   },
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "TPemqfOoGl-C"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# XGBoost\n",
    "params_xgboost = {'xgbclassifier__n_estimators': [100, 200], 'xgbclassifier__learning_rate': [0.01, 0.1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "nYvHBMYIG7PN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      " Working on : {'randomundersampler__sampling_strategy': (0.8, 0.7, 0.6), 'xgbclassifier__n_estimators': [100, 200], 'xgbclassifier__learning_rate': [0.01, 0.1]}\n",
      "Best_score : 0.8874559684859112\n",
      "Best_params : {'randomundersampler__sampling_strategy': 0.6, 'xgbclassifier__learning_rate': 0.1, 'xgbclassifier__n_estimators': 100}\n",
      "--------------------------------------------------------------------------\n",
      " Working on : {'randomoversampler__sampling_strategy': (0.4, 0.5, 0.7), 'xgbclassifier__n_estimators': [100, 200], 'xgbclassifier__learning_rate': [0.01, 0.1]}\n",
      "Best_score : 0.8878167144158385\n",
      "Best_params : {'randomoversampler__sampling_strategy': 0.4, 'xgbclassifier__learning_rate': 0.1, 'xgbclassifier__n_estimators': 100}\n",
      "--------------------------------------------------------------------------\n",
      " Working on : {'xgbclassifier__n_estimators': [100, 200], 'xgbclassifier__learning_rate': [0.01, 0.1]}\n",
      "Best_score : 0.885589393353599\n",
      "Best_params : {'xgbclassifier__learning_rate': 0.1, 'xgbclassifier__n_estimators': 100}\n",
      "CPU times: total: 10min 7s\n",
      "Wall time: 7min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgboost = pipelines_and_search(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), params_sampler, params_xgboost, X_train, y_train, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "4toig9xnG_78"
   },
   "outputs": [],
   "source": [
    "\n",
    "best_xgboost_index = pd.DataFrame({\"Best_score\" : xgboost[0]}).sort_values(by = 'Best_score',\n",
    "                                                                   ascending = False).index[0]\n",
    "best_xgboost = xgboost[1][best_xgboost_index].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "7XEk6IAcHPo6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_preprocess&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;CreditScore&#x27;, &#x27;Age&#x27;,\n",
       "                                                   &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                                   &#x27;IsActiveMember&#x27;,\n",
       "                                                   &#x27;EstimatedSalary&#x27;]),\n",
       "                                                 (&#x27;categorical_preprocess&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                                  [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])),\n",
       "                (&#x27;randomoversampler&#x27;,\n",
       "                 RandomOverSampler(random_state=42...\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.1,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=100, n_jobs=None,\n",
       "                               num_parallel_tree=None, random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_preprocess&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;CreditScore&#x27;, &#x27;Age&#x27;,\n",
       "                                                   &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                                   &#x27;IsActiveMember&#x27;,\n",
       "                                                   &#x27;EstimatedSalary&#x27;]),\n",
       "                                                 (&#x27;categorical_preprocess&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                                  [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])),\n",
       "                (&#x27;randomoversampler&#x27;,\n",
       "                 RandomOverSampler(random_state=42...\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.1,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=100, n_jobs=None,\n",
       "                               num_parallel_tree=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numerical_preprocess&#x27;, StandardScaler(),\n",
       "                                 [&#x27;CreditScore&#x27;, &#x27;Age&#x27;, &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                  &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                  &#x27;IsActiveMember&#x27;, &#x27;EstimatedSalary&#x27;]),\n",
       "                                (&#x27;categorical_preprocess&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                 [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_preprocess</label><div class=\"sk-toggleable__content\"><pre>[&#x27;CreditScore&#x27;, &#x27;Age&#x27;, &#x27;Tenure&#x27;, &#x27;Balance&#x27;, &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;, &#x27;IsActiveMember&#x27;, &#x27;EstimatedSalary&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical_preprocess</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Geography&#x27;, &#x27;Gender&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=42, sampling_strategy=0.4)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('numerical_preprocess',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['CreditScore', 'Age',\n",
       "                                                   'Tenure', 'Balance',\n",
       "                                                   'NumOfProducts', 'HasCrCard',\n",
       "                                                   'IsActiveMember',\n",
       "                                                   'EstimatedSalary']),\n",
       "                                                 ('categorical_preprocess',\n",
       "                                                  OneHotEncoder(drop='first'),\n",
       "                                                  ['Geography', 'Gender'])])),\n",
       "                ('randomoversampler',\n",
       "                 RandomOverSampler(random_state=42...\n",
       "                               feature_types=None, gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.1,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=100, n_jobs=None,\n",
       "                               num_parallel_tree=None, random_state=None, ...))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_names = [name for name, _ in best_xgboost.steps]\n",
    "\n",
    "train_auc_XGB = roc_auc_score(y_train, best_xgboost.predict_proba(X_train)[:, 1])\n",
    "test_auc_XGB = roc_auc_score(y_test, best_xgboost.predict_proba(X_test)[:, 1])\n",
    "model = step_names[1] + \" + \" +  step_names[-1]\n",
    "\n",
    "train_auc.append(train_auc_XGB)\n",
    "test_auc.append(test_auc_XGB)\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>avg_pre</th>\n",
       "      <th>avg_rec</th>\n",
       "      <th>avg_spe</th>\n",
       "      <th>avg_f1</th>\n",
       "      <th>avg_geo</th>\n",
       "      <th>avg_iba</th>\n",
       "      <th>total_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pre</th>\n",
       "      <td>0.902113</td>\n",
       "      <td>0.692171</td>\n",
       "      <td>0.857691</td>\n",
       "      <td>0.861945</td>\n",
       "      <td>0.68924</td>\n",
       "      <td>0.85935</td>\n",
       "      <td>0.761007</td>\n",
       "      <td>0.589134</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec</th>\n",
       "      <td>0.925297</td>\n",
       "      <td>0.625888</td>\n",
       "      <td>0.857691</td>\n",
       "      <td>0.861945</td>\n",
       "      <td>0.68924</td>\n",
       "      <td>0.85935</td>\n",
       "      <td>0.761007</td>\n",
       "      <td>0.589134</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spe</th>\n",
       "      <td>0.625888</td>\n",
       "      <td>0.925297</td>\n",
       "      <td>0.857691</td>\n",
       "      <td>0.861945</td>\n",
       "      <td>0.68924</td>\n",
       "      <td>0.85935</td>\n",
       "      <td>0.761007</td>\n",
       "      <td>0.589134</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.913558</td>\n",
       "      <td>0.657363</td>\n",
       "      <td>0.857691</td>\n",
       "      <td>0.861945</td>\n",
       "      <td>0.68924</td>\n",
       "      <td>0.85935</td>\n",
       "      <td>0.761007</td>\n",
       "      <td>0.589134</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo</th>\n",
       "      <td>0.761007</td>\n",
       "      <td>0.761007</td>\n",
       "      <td>0.857691</td>\n",
       "      <td>0.861945</td>\n",
       "      <td>0.68924</td>\n",
       "      <td>0.85935</td>\n",
       "      <td>0.761007</td>\n",
       "      <td>0.589134</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iba</th>\n",
       "      <td>0.596472</td>\n",
       "      <td>0.561793</td>\n",
       "      <td>0.857691</td>\n",
       "      <td>0.861945</td>\n",
       "      <td>0.68924</td>\n",
       "      <td>0.85935</td>\n",
       "      <td>0.761007</td>\n",
       "      <td>0.589134</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sup</th>\n",
       "      <td>32529.000000</td>\n",
       "      <td>8730.000000</td>\n",
       "      <td>0.857691</td>\n",
       "      <td>0.861945</td>\n",
       "      <td>0.68924</td>\n",
       "      <td>0.85935</td>\n",
       "      <td>0.761007</td>\n",
       "      <td>0.589134</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1   avg_pre   avg_rec  avg_spe   avg_f1  \\\n",
       "pre      0.902113     0.692171  0.857691  0.861945  0.68924  0.85935   \n",
       "rec      0.925297     0.625888  0.857691  0.861945  0.68924  0.85935   \n",
       "spe      0.625888     0.925297  0.857691  0.861945  0.68924  0.85935   \n",
       "f1       0.913558     0.657363  0.857691  0.861945  0.68924  0.85935   \n",
       "geo      0.761007     0.761007  0.857691  0.861945  0.68924  0.85935   \n",
       "iba      0.596472     0.561793  0.857691  0.861945  0.68924  0.85935   \n",
       "sup  32529.000000  8730.000000  0.857691  0.861945  0.68924  0.85935   \n",
       "\n",
       "      avg_geo   avg_iba  total_support  \n",
       "pre  0.761007  0.589134          41259  \n",
       "rec  0.761007  0.589134          41259  \n",
       "spe  0.761007  0.589134          41259  \n",
       "f1   0.761007  0.589134          41259  \n",
       "geo  0.761007  0.589134          41259  \n",
       "iba  0.761007  0.589134          41259  \n",
       "sup  0.761007  0.589134          41259  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report_imbalanced(y_test, best_xgboost.predict(X_test), output_dict = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, best_xgboost.predict(X_test), normalize=\"true\"),\n",
    "           annot=True, fmt='.2g', cmap=\"Greens\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNoI3cQPvLiC"
   },
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "8fTtKysXHWra"
   },
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "params_lgbm = {'lgbmclassifier__learning_rate': [0.01, 0.1, 0.05]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "id": "GRl2xu4fHWui",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      " Working on : {'randomundersampler__sampling_strategy': (0.8, 0.7, 0.6), 'lgbmclassifier__learning_rate': [0.01, 0.1, 0.05]}\n",
      "[LightGBM] [Info] Number of positive: 17460, number of negative: 21825\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 39285, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223144\n",
      "[LightGBM] [Info] Start training from score -0.223144\n",
      "[LightGBM] [Info] Number of positive: 17461, number of negative: 21826\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 39287, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444447 -> initscore=-0.223132\n",
      "[LightGBM] [Info] Start training from score -0.223132\n",
      "[LightGBM] [Info] Number of positive: 17461, number of negative: 21826\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 39287, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444447 -> initscore=-0.223132\n",
      "[LightGBM] [Info] Start training from score -0.223132\n",
      "[LightGBM] [Info] Number of positive: 17460, number of negative: 24942\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 42402, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.411773 -> initscore=-0.356641\n",
      "[LightGBM] [Info] Start training from score -0.356641\n",
      "[LightGBM] [Info] Number of positive: 17461, number of negative: 24944\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 42405, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.411767 -> initscore=-0.356663\n",
      "[LightGBM] [Info] Start training from score -0.356663\n",
      "[LightGBM] [Info] Number of positive: 17461, number of negative: 24944\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 42405, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.411767 -> initscore=-0.356663\n",
      "[LightGBM] [Info] Start training from score -0.356663\n",
      "[LightGBM] [Info] Number of positive: 17460, number of negative: 29100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 46560, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.375000 -> initscore=-0.510826\n",
      "[LightGBM] [Info] Start training from score -0.510826\n",
      "[LightGBM] [Info] Number of positive: 17461, number of negative: 29101\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 46562, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.375005 -> initscore=-0.510803\n",
      "[LightGBM] [Info] Start training from score -0.510803\n",
      "[LightGBM] [Info] Number of positive: 17461, number of negative: 29101\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 46562, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.375005 -> initscore=-0.510803\n",
      "[LightGBM] [Info] Start training from score -0.510803\n",
      "[LightGBM] [Info] Number of positive: 17460, number of negative: 21825\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 39285, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223144\n",
      "[LightGBM] [Info] Start training from score -0.223144\n",
      "[LightGBM] [Info] Number of positive: 17461, number of negative: 21826\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 39287, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444447 -> initscore=-0.223132\n",
      "[LightGBM] [Info] Start training from score -0.223132\n",
      "[LightGBM] [Info] Number of positive: 17461, number of negative: 21826\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 39287, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444447 -> initscore=-0.223132\n",
      "[LightGBM] [Info] Start training from score -0.223132\n",
      "[LightGBM] [Info] Number of positive: 17460, number of negative: 24942\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 42402, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.411773 -> initscore=-0.356641\n",
      "[LightGBM] [Info] Start training from score -0.356641\n",
      "[LightGBM] [Info] Number of positive: 17461, number of negative: 24944\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 42405, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.411767 -> initscore=-0.356663\n",
      "[LightGBM] [Info] Start training from score -0.356663\n",
      "[LightGBM] [Info] Number of positive: 17461, number of negative: 24944\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 42405, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.411767 -> initscore=-0.356663\n",
      "[LightGBM] [Info] Start training from score -0.356663\n",
      "[LightGBM] [Info] Number of positive: 17460, number of negative: 29100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 46560, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.375000 -> initscore=-0.510826\n",
      "[LightGBM] [Info] Start training from score -0.510826\n",
      "[LightGBM] [Info] Number of positive: 17461, number of negative: 29101\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 46562, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.375005 -> initscore=-0.510803\n",
      "[LightGBM] [Info] Start training from score -0.510803\n",
      "[LightGBM] [Info] Number of positive: 17461, number of negative: 29101\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 46562, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.375005 -> initscore=-0.510803\n",
      "[LightGBM] [Info] Start training from score -0.510803\n",
      "[LightGBM] [Info] Number of positive: 17460, number of negative: 21825\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 39285, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444444 -> initscore=-0.223144\n",
      "[LightGBM] [Info] Start training from score -0.223144\n",
      "[LightGBM] [Info] Number of positive: 17461, number of negative: 21826\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 39287, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444447 -> initscore=-0.223132\n",
      "[LightGBM] [Info] Start training from score -0.223132\n",
      "[LightGBM] [Info] Number of positive: 17461, number of negative: 21826\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 39287, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444447 -> initscore=-0.223132\n",
      "[LightGBM] [Info] Start training from score -0.223132\n",
      "[LightGBM] [Info] Number of positive: 17460, number of negative: 24942\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 42402, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.411773 -> initscore=-0.356641\n",
      "[LightGBM] [Info] Start training from score -0.356641\n",
      "[LightGBM] [Info] Number of positive: 17461, number of negative: 24944\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 42405, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.411767 -> initscore=-0.356663\n",
      "[LightGBM] [Info] Start training from score -0.356663\n",
      "[LightGBM] [Info] Number of positive: 17461, number of negative: 24944\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 42405, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.411767 -> initscore=-0.356663\n",
      "[LightGBM] [Info] Start training from score -0.356663\n",
      "[LightGBM] [Info] Number of positive: 17460, number of negative: 29100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 46560, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.375000 -> initscore=-0.510826\n",
      "[LightGBM] [Info] Start training from score -0.510826\n",
      "[LightGBM] [Info] Number of positive: 17461, number of negative: 29101\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 46562, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.375005 -> initscore=-0.510803\n",
      "[LightGBM] [Info] Start training from score -0.510803\n",
      "[LightGBM] [Info] Number of positive: 17461, number of negative: 29101\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 46562, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.375005 -> initscore=-0.510803\n",
      "[LightGBM] [Info] Start training from score -0.510803\n",
      "[LightGBM] [Info] Number of positive: 26191, number of negative: 43651\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 69842, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.375004 -> initscore=-0.510810\n",
      "[LightGBM] [Info] Start training from score -0.510810\n",
      "Best_score : 0.8881931327934144\n",
      "Best_params : {'lgbmclassifier__learning_rate': 0.05, 'randomundersampler__sampling_strategy': 0.6}\n",
      "--------------------------------------------------------------------------\n",
      " Working on : {'randomoversampler__sampling_strategy': (0.4, 0.5, 0.7), 'lgbmclassifier__learning_rate': [0.01, 0.1, 0.05]}\n",
      "[LightGBM] [Info] Number of positive: 26022, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 91078, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.285711 -> initscore=-0.916306\n",
      "[LightGBM] [Info] Start training from score -0.916306\n",
      "[LightGBM] [Info] Number of positive: 26022, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 91078, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.285711 -> initscore=-0.916306\n",
      "[LightGBM] [Info] Start training from score -0.916306\n",
      "[LightGBM] [Info] Number of positive: 26022, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 91078, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.285711 -> initscore=-0.916306\n",
      "[LightGBM] [Info] Start training from score -0.916306\n",
      "[LightGBM] [Info] Number of positive: 32528, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 97584, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "[LightGBM] [Info] Number of positive: 32528, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 862\n",
      "[LightGBM] [Info] Number of data points in the train set: 97584, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "[LightGBM] [Info] Number of positive: 32528, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 97584, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "[LightGBM] [Info] Number of positive: 45539, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 110595, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.411764 -> initscore=-0.356679\n",
      "[LightGBM] [Info] Start training from score -0.356679\n",
      "[LightGBM] [Info] Number of positive: 45539, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 110595, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.411764 -> initscore=-0.356679\n",
      "[LightGBM] [Info] Start training from score -0.356679\n",
      "[LightGBM] [Info] Number of positive: 45539, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 862\n",
      "[LightGBM] [Info] Number of data points in the train set: 110595, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.411764 -> initscore=-0.356679\n",
      "[LightGBM] [Info] Start training from score -0.356679\n",
      "[LightGBM] [Info] Number of positive: 26022, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 91078, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.285711 -> initscore=-0.916306\n",
      "[LightGBM] [Info] Start training from score -0.916306\n",
      "[LightGBM] [Info] Number of positive: 26022, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 91078, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.285711 -> initscore=-0.916306\n",
      "[LightGBM] [Info] Start training from score -0.916306\n",
      "[LightGBM] [Info] Number of positive: 26022, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 91078, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.285711 -> initscore=-0.916306\n",
      "[LightGBM] [Info] Start training from score -0.916306\n",
      "[LightGBM] [Info] Number of positive: 32528, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 97584, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "[LightGBM] [Info] Number of positive: 32528, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 862\n",
      "[LightGBM] [Info] Number of data points in the train set: 97584, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "[LightGBM] [Info] Number of positive: 32528, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 97584, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "[LightGBM] [Info] Number of positive: 45539, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 110595, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.411764 -> initscore=-0.356679\n",
      "[LightGBM] [Info] Start training from score -0.356679\n",
      "[LightGBM] [Info] Number of positive: 45539, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 110595, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.411764 -> initscore=-0.356679\n",
      "[LightGBM] [Info] Start training from score -0.356679\n",
      "[LightGBM] [Info] Number of positive: 45539, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 862\n",
      "[LightGBM] [Info] Number of data points in the train set: 110595, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.411764 -> initscore=-0.356679\n",
      "[LightGBM] [Info] Start training from score -0.356679\n",
      "[LightGBM] [Info] Number of positive: 26022, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 91078, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.285711 -> initscore=-0.916306\n",
      "[LightGBM] [Info] Start training from score -0.916306\n",
      "[LightGBM] [Info] Number of positive: 26022, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 91078, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.285711 -> initscore=-0.916306\n",
      "[LightGBM] [Info] Start training from score -0.916306\n",
      "[LightGBM] [Info] Number of positive: 26022, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 91078, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.285711 -> initscore=-0.916306\n",
      "[LightGBM] [Info] Start training from score -0.916306\n",
      "[LightGBM] [Info] Number of positive: 32528, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 97584, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "[LightGBM] [Info] Number of positive: 32528, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 862\n",
      "[LightGBM] [Info] Number of data points in the train set: 97584, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "[LightGBM] [Info] Number of positive: 32528, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 97584, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "[LightGBM] [Info] Number of positive: 45539, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 110595, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.411764 -> initscore=-0.356679\n",
      "[LightGBM] [Info] Start training from score -0.356679\n",
      "[LightGBM] [Info] Number of positive: 45539, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 861\n",
      "[LightGBM] [Info] Number of data points in the train set: 110595, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.411764 -> initscore=-0.356679\n",
      "[LightGBM] [Info] Start training from score -0.356679\n",
      "[LightGBM] [Info] Number of positive: 45539, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 862\n",
      "[LightGBM] [Info] Number of data points in the train set: 110595, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.411764 -> initscore=-0.356679\n",
      "[LightGBM] [Info] Start training from score -0.356679\n",
      "[LightGBM] [Info] Number of positive: 39033, number of negative: 97584\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 862\n",
      "[LightGBM] [Info] Number of data points in the train set: 136617, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.285711 -> initscore=-0.916306\n",
      "[LightGBM] [Info] Start training from score -0.916306\n",
      "Best_score : 0.8882689665122546\n",
      "Best_params : {'lgbmclassifier__learning_rate': 0.05, 'randomoversampler__sampling_strategy': 0.4}\n",
      "--------------------------------------------------------------------------\n",
      " Working on : {'lgbmclassifier__learning_rate': [0.01, 0.1, 0.05]}\n",
      "[LightGBM] [Info] Number of positive: 65056, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2114\n",
      "[LightGBM] [Info] Number of data points in the train set: 130112, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 65056, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2119\n",
      "[LightGBM] [Info] Number of data points in the train set: 130112, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 65056, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2115\n",
      "[LightGBM] [Info] Number of data points in the train set: 130112, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 65056, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2107\n",
      "[LightGBM] [Info] Number of data points in the train set: 130112, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 65056, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2103\n",
      "[LightGBM] [Info] Number of data points in the train set: 130112, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 65056, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2116\n",
      "[LightGBM] [Info] Number of data points in the train set: 130112, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 65056, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2117\n",
      "[LightGBM] [Info] Number of data points in the train set: 130112, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 65056, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2111\n",
      "[LightGBM] [Info] Number of data points in the train set: 130112, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 65056, number of negative: 65056\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2116\n",
      "[LightGBM] [Info] Number of data points in the train set: 130112, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 97584, number of negative: 97584\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 195168, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Best_score : 0.8872498839096291\n",
      "Best_params : {'lgbmclassifier__learning_rate': 0.1}\n",
      "CPU times: total: 4min 23s\n",
      "Wall time: 2min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lightgbm_model = pipelines_and_search(LGBMClassifier(), params_sampler, params_lgbm, X_train, y_train, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "_3Y7JMC-HWxE"
   },
   "outputs": [],
   "source": [
    "best_lightgbm_model = pd.DataFrame({\"Best_score\" : lightgbm_model[0]}).sort_values(by = 'Best_score',\n",
    "                                                                   ascending = False).index[0]\n",
    "best_lightgbm_model = lightgbm_model[1][best_model_index].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "rN8ZG9vUH2AZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_preprocess&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;CreditScore&#x27;, &#x27;Age&#x27;,\n",
       "                                                   &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                                   &#x27;IsActiveMember&#x27;,\n",
       "                                                   &#x27;EstimatedSalary&#x27;]),\n",
       "                                                 (&#x27;categorical_preprocess&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                                  [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])),\n",
       "                (&#x27;randomundersampler&#x27;,\n",
       "                 RandomUnderSampler(random_state=42, sampling_strategy=0.6)),\n",
       "                (&#x27;lgbmclassifier&#x27;, LGBMClassifier(learning_rate=0.05))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_preprocess&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;CreditScore&#x27;, &#x27;Age&#x27;,\n",
       "                                                   &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                                   &#x27;IsActiveMember&#x27;,\n",
       "                                                   &#x27;EstimatedSalary&#x27;]),\n",
       "                                                 (&#x27;categorical_preprocess&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                                  [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])),\n",
       "                (&#x27;randomundersampler&#x27;,\n",
       "                 RandomUnderSampler(random_state=42, sampling_strategy=0.6)),\n",
       "                (&#x27;lgbmclassifier&#x27;, LGBMClassifier(learning_rate=0.05))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numerical_preprocess&#x27;, StandardScaler(),\n",
       "                                 [&#x27;CreditScore&#x27;, &#x27;Age&#x27;, &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                  &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                  &#x27;IsActiveMember&#x27;, &#x27;EstimatedSalary&#x27;]),\n",
       "                                (&#x27;categorical_preprocess&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                 [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_preprocess</label><div class=\"sk-toggleable__content\"><pre>[&#x27;CreditScore&#x27;, &#x27;Age&#x27;, &#x27;Tenure&#x27;, &#x27;Balance&#x27;, &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;, &#x27;IsActiveMember&#x27;, &#x27;EstimatedSalary&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical_preprocess</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Geography&#x27;, &#x27;Gender&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=42, sampling_strategy=0.6)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" ><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.05)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('numerical_preprocess',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['CreditScore', 'Age',\n",
       "                                                   'Tenure', 'Balance',\n",
       "                                                   'NumOfProducts', 'HasCrCard',\n",
       "                                                   'IsActiveMember',\n",
       "                                                   'EstimatedSalary']),\n",
       "                                                 ('categorical_preprocess',\n",
       "                                                  OneHotEncoder(drop='first'),\n",
       "                                                  ['Geography', 'Gender'])])),\n",
       "                ('randomundersampler',\n",
       "                 RandomUnderSampler(random_state=42, sampling_strategy=0.6)),\n",
       "                ('lgbmclassifier', LGBMClassifier(learning_rate=0.05))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lightgbm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_names = [name for name, _ in best_lightgbm_model.steps]\n",
    "\n",
    "train_auc_LGB = roc_auc_score(y_train, best_lightgbm_model.predict_proba(X_train)[:, 1])\n",
    "test_auc_LGB = roc_auc_score(y_test, best_lightgbm_model.predict_proba(X_test)[:, 1])\n",
    "model = step_names[1] + \" + \" +  step_names[-1]\n",
    "\n",
    "train_auc.append(train_auc_LGB)\n",
    "test_auc.append(test_auc_LGB)\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>avg_pre</th>\n",
       "      <th>avg_rec</th>\n",
       "      <th>avg_spe</th>\n",
       "      <th>avg_f1</th>\n",
       "      <th>avg_geo</th>\n",
       "      <th>avg_iba</th>\n",
       "      <th>total_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pre</th>\n",
       "      <td>0.917832</td>\n",
       "      <td>0.627105</td>\n",
       "      <td>0.856317</td>\n",
       "      <td>0.848785</td>\n",
       "      <td>0.74278</td>\n",
       "      <td>0.851883</td>\n",
       "      <td>0.790459</td>\n",
       "      <td>0.631449</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec</th>\n",
       "      <td>0.887669</td>\n",
       "      <td>0.703895</td>\n",
       "      <td>0.856317</td>\n",
       "      <td>0.848785</td>\n",
       "      <td>0.74278</td>\n",
       "      <td>0.851883</td>\n",
       "      <td>0.790459</td>\n",
       "      <td>0.631449</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spe</th>\n",
       "      <td>0.703895</td>\n",
       "      <td>0.887669</td>\n",
       "      <td>0.856317</td>\n",
       "      <td>0.848785</td>\n",
       "      <td>0.74278</td>\n",
       "      <td>0.851883</td>\n",
       "      <td>0.790459</td>\n",
       "      <td>0.631449</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.902499</td>\n",
       "      <td>0.663285</td>\n",
       "      <td>0.856317</td>\n",
       "      <td>0.848785</td>\n",
       "      <td>0.74278</td>\n",
       "      <td>0.851883</td>\n",
       "      <td>0.790459</td>\n",
       "      <td>0.631449</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo</th>\n",
       "      <td>0.790459</td>\n",
       "      <td>0.790459</td>\n",
       "      <td>0.856317</td>\n",
       "      <td>0.848785</td>\n",
       "      <td>0.74278</td>\n",
       "      <td>0.851883</td>\n",
       "      <td>0.790459</td>\n",
       "      <td>0.631449</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iba</th>\n",
       "      <td>0.636308</td>\n",
       "      <td>0.613343</td>\n",
       "      <td>0.856317</td>\n",
       "      <td>0.848785</td>\n",
       "      <td>0.74278</td>\n",
       "      <td>0.851883</td>\n",
       "      <td>0.790459</td>\n",
       "      <td>0.631449</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sup</th>\n",
       "      <td>32529.000000</td>\n",
       "      <td>8730.000000</td>\n",
       "      <td>0.856317</td>\n",
       "      <td>0.848785</td>\n",
       "      <td>0.74278</td>\n",
       "      <td>0.851883</td>\n",
       "      <td>0.790459</td>\n",
       "      <td>0.631449</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1   avg_pre   avg_rec  avg_spe    avg_f1  \\\n",
       "pre      0.917832     0.627105  0.856317  0.848785  0.74278  0.851883   \n",
       "rec      0.887669     0.703895  0.856317  0.848785  0.74278  0.851883   \n",
       "spe      0.703895     0.887669  0.856317  0.848785  0.74278  0.851883   \n",
       "f1       0.902499     0.663285  0.856317  0.848785  0.74278  0.851883   \n",
       "geo      0.790459     0.790459  0.856317  0.848785  0.74278  0.851883   \n",
       "iba      0.636308     0.613343  0.856317  0.848785  0.74278  0.851883   \n",
       "sup  32529.000000  8730.000000  0.856317  0.848785  0.74278  0.851883   \n",
       "\n",
       "      avg_geo   avg_iba  total_support  \n",
       "pre  0.790459  0.631449          41259  \n",
       "rec  0.790459  0.631449          41259  \n",
       "spe  0.790459  0.631449          41259  \n",
       "f1   0.790459  0.631449          41259  \n",
       "geo  0.790459  0.631449          41259  \n",
       "iba  0.790459  0.631449          41259  \n",
       "sup  0.790459  0.631449          41259  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report_imbalanced(y_test, best_lightgbm_model.predict(X_test), output_dict = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, best_lightgbm_model.predict(X_test), normalize=\"true\"),\n",
    "           annot=True, fmt='.2g', cmap=\"Greens\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slAggIhIKZ1P"
   },
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "PgmhHcreKc7_"
   },
   "outputs": [],
   "source": [
    "# Perceptron\n",
    "params_perceptron = {'perceptron__penalty': ['l2', 'l1'], 'perceptron__alpha': [0.001, 0.01]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "pwYdOu7WKgKL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      " Working on : {'randomundersampler__sampling_strategy': (0.8, 0.7, 0.6), 'perceptron__penalty': ['l2', 'l1'], 'perceptron__alpha': [0.001, 0.01]}\n",
      "Best_score : 0.7494856586780703\n",
      "Best_params : {'perceptron__alpha': 0.001, 'perceptron__penalty': 'l1', 'randomundersampler__sampling_strategy': 0.7}\n",
      "--------------------------------------------------------------------------\n",
      " Working on : {'randomoversampler__sampling_strategy': (0.4, 0.5, 0.7), 'perceptron__penalty': ['l2', 'l1'], 'perceptron__alpha': [0.001, 0.01]}\n",
      "Best_score : 0.7822797670846344\n",
      "Best_params : {'perceptron__alpha': 0.01, 'perceptron__penalty': 'l1', 'randomoversampler__sampling_strategy': 0.4}\n",
      "--------------------------------------------------------------------------\n",
      " Working on : {'perceptron__penalty': ['l2', 'l1'], 'perceptron__alpha': [0.001, 0.01]}\n",
      "Best_score : 0.772732448730021\n",
      "Best_params : {'perceptron__alpha': 0.001, 'perceptron__penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "perceptron = pipelines_and_search(Perceptron(), params_sampler, params_perceptron, X_train, y_train, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "_3Y7JMC-HWxE"
   },
   "outputs": [],
   "source": [
    "best_perceptron_model_index = pd.DataFrame({\"Best_score\" : perceptron[0]}).sort_values(by = 'Best_score',\n",
    "                                                                   ascending = False).index[0]\n",
    "best_perceptron_model= perceptron[1][best_perceptron_model_index].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "rN8ZG9vUH2AZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_preprocess&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;CreditScore&#x27;, &#x27;Age&#x27;,\n",
       "                                                   &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                                   &#x27;IsActiveMember&#x27;,\n",
       "                                                   &#x27;EstimatedSalary&#x27;]),\n",
       "                                                 (&#x27;categorical_preprocess&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                                  [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])),\n",
       "                (&#x27;randomoversampler&#x27;,\n",
       "                 RandomOverSampler(random_state=42, sampling_strategy=0.4)),\n",
       "                (&#x27;perceptron&#x27;, Perceptron(alpha=0.01, penalty=&#x27;l1&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" ><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_preprocess&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;CreditScore&#x27;, &#x27;Age&#x27;,\n",
       "                                                   &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                                   &#x27;IsActiveMember&#x27;,\n",
       "                                                   &#x27;EstimatedSalary&#x27;]),\n",
       "                                                 (&#x27;categorical_preprocess&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                                  [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])),\n",
       "                (&#x27;randomoversampler&#x27;,\n",
       "                 RandomOverSampler(random_state=42, sampling_strategy=0.4)),\n",
       "                (&#x27;perceptron&#x27;, Perceptron(alpha=0.01, penalty=&#x27;l1&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numerical_preprocess&#x27;, StandardScaler(),\n",
       "                                 [&#x27;CreditScore&#x27;, &#x27;Age&#x27;, &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                  &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                  &#x27;IsActiveMember&#x27;, &#x27;EstimatedSalary&#x27;]),\n",
       "                                (&#x27;categorical_preprocess&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                 [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_preprocess</label><div class=\"sk-toggleable__content\"><pre>[&#x27;CreditScore&#x27;, &#x27;Age&#x27;, &#x27;Tenure&#x27;, &#x27;Balance&#x27;, &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;, &#x27;IsActiveMember&#x27;, &#x27;EstimatedSalary&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical_preprocess</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Geography&#x27;, &#x27;Gender&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" ><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" ><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=42, sampling_strategy=0.4)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron(alpha=0.01, penalty=&#x27;l1&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('numerical_preprocess',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['CreditScore', 'Age',\n",
       "                                                   'Tenure', 'Balance',\n",
       "                                                   'NumOfProducts', 'HasCrCard',\n",
       "                                                   'IsActiveMember',\n",
       "                                                   'EstimatedSalary']),\n",
       "                                                 ('categorical_preprocess',\n",
       "                                                  OneHotEncoder(drop='first'),\n",
       "                                                  ['Geography', 'Gender'])])),\n",
       "                ('randomoversampler',\n",
       "                 RandomOverSampler(random_state=42, sampling_strategy=0.4)),\n",
       "                ('perceptron', Perceptron(alpha=0.01, penalty='l1'))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_perceptron_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstep_names = [name for name, _ in best_perceptron_model.steps]\\n\\ntrain_auc_perceptron = roc_auc_score(y_train, best_perceptron_model.predict_proba(X_train)[:, 1])\\ntest_auc_perceptron = roc_auc_score(y_test, best_perceptron_model.predict_proba(X_test)[:, 1])\\nmodel = step_names[1] + \" + \" +  step_names[-1]\\n\\ntrain_auc.append(train_auc_perceptron)\\ntest_auc.append(test_auc_perceptron)\\nmodels.append(model)\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "step_names = [name for name, _ in best_perceptron_model.steps]\n",
    "\n",
    "train_auc_perceptron = roc_auc_score(y_train, best_perceptron_model.predict_proba(X_train)[:, 1])\n",
    "test_auc_perceptron = roc_auc_score(y_test, best_perceptron_model.predict_proba(X_test)[:, 1])\n",
    "model = step_names[1] + \" + \" +  step_names[-1]\n",
    "\n",
    "train_auc.append(train_auc_perceptron)\n",
    "test_auc.append(test_auc_perceptron)\n",
    "models.append(model)\n",
    "\"\"\"\n",
    "\n",
    "# Pas de méthode Predict.proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>avg_pre</th>\n",
       "      <th>avg_rec</th>\n",
       "      <th>avg_spe</th>\n",
       "      <th>avg_f1</th>\n",
       "      <th>avg_geo</th>\n",
       "      <th>avg_iba</th>\n",
       "      <th>total_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pre</th>\n",
       "      <td>0.925097</td>\n",
       "      <td>0.373768</td>\n",
       "      <td>0.808441</td>\n",
       "      <td>0.672944</td>\n",
       "      <td>0.771684</td>\n",
       "      <td>0.702829</td>\n",
       "      <td>0.717225</td>\n",
       "      <td>0.509333</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec</th>\n",
       "      <td>0.636724</td>\n",
       "      <td>0.807904</td>\n",
       "      <td>0.808441</td>\n",
       "      <td>0.672944</td>\n",
       "      <td>0.771684</td>\n",
       "      <td>0.702829</td>\n",
       "      <td>0.717225</td>\n",
       "      <td>0.509333</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spe</th>\n",
       "      <td>0.807904</td>\n",
       "      <td>0.636724</td>\n",
       "      <td>0.808441</td>\n",
       "      <td>0.672944</td>\n",
       "      <td>0.771684</td>\n",
       "      <td>0.702829</td>\n",
       "      <td>0.717225</td>\n",
       "      <td>0.509333</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.754288</td>\n",
       "      <td>0.511087</td>\n",
       "      <td>0.808441</td>\n",
       "      <td>0.672944</td>\n",
       "      <td>0.771684</td>\n",
       "      <td>0.702829</td>\n",
       "      <td>0.717225</td>\n",
       "      <td>0.509333</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo</th>\n",
       "      <td>0.717225</td>\n",
       "      <td>0.717225</td>\n",
       "      <td>0.808441</td>\n",
       "      <td>0.672944</td>\n",
       "      <td>0.771684</td>\n",
       "      <td>0.702829</td>\n",
       "      <td>0.717225</td>\n",
       "      <td>0.509333</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iba</th>\n",
       "      <td>0.505606</td>\n",
       "      <td>0.523218</td>\n",
       "      <td>0.808441</td>\n",
       "      <td>0.672944</td>\n",
       "      <td>0.771684</td>\n",
       "      <td>0.702829</td>\n",
       "      <td>0.717225</td>\n",
       "      <td>0.509333</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sup</th>\n",
       "      <td>32529.000000</td>\n",
       "      <td>8730.000000</td>\n",
       "      <td>0.808441</td>\n",
       "      <td>0.672944</td>\n",
       "      <td>0.771684</td>\n",
       "      <td>0.702829</td>\n",
       "      <td>0.717225</td>\n",
       "      <td>0.509333</td>\n",
       "      <td>41259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1   avg_pre   avg_rec   avg_spe    avg_f1  \\\n",
       "pre      0.925097     0.373768  0.808441  0.672944  0.771684  0.702829   \n",
       "rec      0.636724     0.807904  0.808441  0.672944  0.771684  0.702829   \n",
       "spe      0.807904     0.636724  0.808441  0.672944  0.771684  0.702829   \n",
       "f1       0.754288     0.511087  0.808441  0.672944  0.771684  0.702829   \n",
       "geo      0.717225     0.717225  0.808441  0.672944  0.771684  0.702829   \n",
       "iba      0.505606     0.523218  0.808441  0.672944  0.771684  0.702829   \n",
       "sup  32529.000000  8730.000000  0.808441  0.672944  0.771684  0.702829   \n",
       "\n",
       "      avg_geo   avg_iba  total_support  \n",
       "pre  0.717225  0.509333          41259  \n",
       "rec  0.717225  0.509333          41259  \n",
       "spe  0.717225  0.509333          41259  \n",
       "f1   0.717225  0.509333          41259  \n",
       "geo  0.717225  0.509333          41259  \n",
       "iba  0.717225  0.509333          41259  \n",
       "sup  0.717225  0.509333          41259  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report_imbalanced(y_test, best_perceptron_model.predict(X_test), output_dict = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, best_perceptron_model.predict(X_test), normalize=\"true\"),\n",
    "           annot=True, fmt='.2g', cmap=\"Greens\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYRaSLS3TJIv"
   },
   "source": [
    "# Comparaison entre les prédictions du meilleur modèle et celle du voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "Jx7gwpixTXaI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smote + logisticregression</td>\n",
       "      <td>0.819705</td>\n",
       "      <td>0.816132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>randomundersampler + gaussiannb</td>\n",
       "      <td>0.817122</td>\n",
       "      <td>0.813029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>randomoversampler + xgbclassifier</td>\n",
       "      <td>0.900426</td>\n",
       "      <td>0.888684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>randomundersampler + lgbmclassifier</td>\n",
       "      <td>0.892261</td>\n",
       "      <td>0.888668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                models  train_auc  test_auc\n",
       "0           smote + logisticregression   0.819705  0.816132\n",
       "1      randomundersampler + gaussiannb   0.817122  0.813029\n",
       "2    randomoversampler + xgbclassifier   0.900426  0.888684\n",
       "3  randomundersampler + lgbmclassifier   0.892261  0.888668"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"models\" : models, 'train_auc' : train_auc, 'test_auc' : test_auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_preprocess&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;CreditScore&#x27;, &#x27;Age&#x27;,\n",
       "                                                   &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                                   &#x27;IsActiveMember&#x27;,\n",
       "                                                   &#x27;EstimatedSalary&#x27;]),\n",
       "                                                 (&#x27;categorical_preprocess&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                                  [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])),\n",
       "                (&#x27;randomundersampler&#x27;,\n",
       "                 RandomUnderSampler(random_state=42, sampling_strategy=0.6)),\n",
       "                (&#x27;lgbmclassifier&#x27;, LGBMClassifier(learning_rate=0.05))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" ><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_preprocess&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;CreditScore&#x27;, &#x27;Age&#x27;,\n",
       "                                                   &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                                   &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                                   &#x27;IsActiveMember&#x27;,\n",
       "                                                   &#x27;EstimatedSalary&#x27;]),\n",
       "                                                 (&#x27;categorical_preprocess&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                                  [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])),\n",
       "                (&#x27;randomundersampler&#x27;,\n",
       "                 RandomUnderSampler(random_state=42, sampling_strategy=0.6)),\n",
       "                (&#x27;lgbmclassifier&#x27;, LGBMClassifier(learning_rate=0.05))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numerical_preprocess&#x27;, StandardScaler(),\n",
       "                                 [&#x27;CreditScore&#x27;, &#x27;Age&#x27;, &#x27;Tenure&#x27;, &#x27;Balance&#x27;,\n",
       "                                  &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;,\n",
       "                                  &#x27;IsActiveMember&#x27;, &#x27;EstimatedSalary&#x27;]),\n",
       "                                (&#x27;categorical_preprocess&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                 [&#x27;Geography&#x27;, &#x27;Gender&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_preprocess</label><div class=\"sk-toggleable__content\"><pre>[&#x27;CreditScore&#x27;, &#x27;Age&#x27;, &#x27;Tenure&#x27;, &#x27;Balance&#x27;, &#x27;NumOfProducts&#x27;, &#x27;HasCrCard&#x27;, &#x27;IsActiveMember&#x27;, &#x27;EstimatedSalary&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical_preprocess</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Geography&#x27;, &#x27;Gender&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=42, sampling_strategy=0.6)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.05)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('numerical_preprocess',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['CreditScore', 'Age',\n",
       "                                                   'Tenure', 'Balance',\n",
       "                                                   'NumOfProducts', 'HasCrCard',\n",
       "                                                   'IsActiveMember',\n",
       "                                                   'EstimatedSalary']),\n",
       "                                                 ('categorical_preprocess',\n",
       "                                                  OneHotEncoder(drop='first'),\n",
       "                                                  ['Geography', 'Gender'])])),\n",
       "                ('randomundersampler',\n",
       "                 RandomUnderSampler(random_state=42, sampling_strategy=0.6)),\n",
       "                ('lgbmclassifier', LGBMClassifier(learning_rate=0.05))])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = best_lightgbm_model\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Or5EFzK-UEN6"
   },
   "source": [
    "### Exportation du meileur modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après évaluation des différentes combinaisons de modèles et techniques d'échantillonnage, le choix s'est porté sur le modèle utilisant le Random UnderSampler avec LightGBM Classifier. Bien que le modèle avec XGBoost affiche un AUC légèrement supérieur sur l'ensemble d'entraînement (0.900426), le LightGBM présente des performances très proches avec un AUC de 0.892261. De plus, les résultats sur l'ensemble de test sont pratiquement équivalents, avec un AUC de 0.888668 pour LightGBM contre 0.888684 pour XGBoost, indiquant une généralisation similaire. La décision de choisir LightGBM repose sur son efficacité en termes de temps de calcul et de ressources, sa capacité à gérer de très grands ensembles de données et sa flexibilité pour ajuster divers hyperparamètres, ce qui le rend particulièrement adapté à notre environnement et à nos besoins opérationnels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "YQk3Zx0FV7bj"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./best_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(best_model, model_file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
